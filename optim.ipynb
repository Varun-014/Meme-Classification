{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = breast_cancer_wisconsin_diagnostic.data.features \n",
    "y = breast_cancer_wisconsin_diagnostic.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(breast_cancer_wisconsin_diagnostic.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(breast_cancer_wisconsin_diagnostic.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.074023</td>\n",
       "      <td>-0.112030</td>\n",
       "      <td>-0.399132</td>\n",
       "      <td>-0.073665</td>\n",
       "      <td>0.476511</td>\n",
       "      <td>0.064854</td>\n",
       "      <td>-0.403069</td>\n",
       "      <td>0.053296</td>\n",
       "      <td>-0.019522</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.423803</td>\n",
       "      <td>0.151787</td>\n",
       "      <td>0.220039</td>\n",
       "      <td>-0.824494</td>\n",
       "      <td>0.382869</td>\n",
       "      <td>0.225207</td>\n",
       "      <td>-0.079887</td>\n",
       "      <td>-0.167158</td>\n",
       "      <td>-0.163683</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.258595</td>\n",
       "      <td>-0.172619</td>\n",
       "      <td>-0.450004</td>\n",
       "      <td>-0.057276</td>\n",
       "      <td>0.449533</td>\n",
       "      <td>0.098879</td>\n",
       "      <td>-0.417169</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>-0.119147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542888</td>\n",
       "      <td>0.493016</td>\n",
       "      <td>0.244294</td>\n",
       "      <td>-0.905777</td>\n",
       "      <td>0.332555</td>\n",
       "      <td>0.341171</td>\n",
       "      <td>-0.250401</td>\n",
       "      <td>-0.318815</td>\n",
       "      <td>-0.180514</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.507778</td>\n",
       "      <td>-0.280582</td>\n",
       "      <td>-0.868544</td>\n",
       "      <td>0.464717</td>\n",
       "      <td>0.201069</td>\n",
       "      <td>-0.036224</td>\n",
       "      <td>0.585509</td>\n",
       "      <td>0.154884</td>\n",
       "      <td>-0.786770</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696650</td>\n",
       "      <td>0.843332</td>\n",
       "      <td>0.491750</td>\n",
       "      <td>-0.194759</td>\n",
       "      <td>-0.260551</td>\n",
       "      <td>0.389322</td>\n",
       "      <td>-0.321516</td>\n",
       "      <td>-0.636744</td>\n",
       "      <td>0.187596</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.373513</td>\n",
       "      <td>-0.237013</td>\n",
       "      <td>0.378660</td>\n",
       "      <td>0.069003</td>\n",
       "      <td>-0.599384</td>\n",
       "      <td>0.063375</td>\n",
       "      <td>0.221117</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.271017</td>\n",
       "      <td>-0.053507</td>\n",
       "      <td>-0.042000</td>\n",
       "      <td>-0.785885</td>\n",
       "      <td>0.280219</td>\n",
       "      <td>0.158491</td>\n",
       "      <td>-0.170124</td>\n",
       "      <td>-0.094134</td>\n",
       "      <td>-0.341412</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.335272</td>\n",
       "      <td>-0.121074</td>\n",
       "      <td>-0.129973</td>\n",
       "      <td>0.181269</td>\n",
       "      <td>-0.272406</td>\n",
       "      <td>-0.059930</td>\n",
       "      <td>0.335254</td>\n",
       "      <td>0.100961</td>\n",
       "      <td>-0.213555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>-0.032603</td>\n",
       "      <td>0.324002</td>\n",
       "      <td>0.167571</td>\n",
       "      <td>-0.071234</td>\n",
       "      <td>0.248293</td>\n",
       "      <td>0.237985</td>\n",
       "      <td>-0.445129</td>\n",
       "      <td>0.144760</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -0.074023 -0.112030 -0.399132 -0.073665  0.476511  0.064854   \n",
       "1           1 -0.258595 -0.172619 -0.450004 -0.057276  0.449533  0.098879   \n",
       "2           2 -0.507778 -0.280582 -0.868544  0.464717  0.201069 -0.036224   \n",
       "3           3  0.085974 -0.011425 -0.373513 -0.237013  0.378660  0.069003   \n",
       "4           4 -0.335272 -0.121074 -0.129973  0.181269 -0.272406 -0.059930   \n",
       "\n",
       "          6         7         8  ...       759       760       761       762  \\\n",
       "0 -0.403069  0.053296 -0.019522  ... -0.423803  0.151787  0.220039 -0.824494   \n",
       "1 -0.417169  0.035035 -0.119147  ... -0.542888  0.493016  0.244294 -0.905777   \n",
       "2  0.585509  0.154884 -0.786770  ... -0.696650  0.843332  0.491750 -0.194759   \n",
       "3 -0.599384  0.063375  0.221117  ... -0.271017 -0.053507 -0.042000 -0.785885   \n",
       "4  0.335254  0.100961 -0.213555  ...  0.020692 -0.032603  0.324002  0.167571   \n",
       "\n",
       "        763       764       765       766       767  Labels  \n",
       "0  0.382869  0.225207 -0.079887 -0.167158 -0.163683     1.0  \n",
       "1  0.332555  0.341171 -0.250401 -0.318815 -0.180514     1.0  \n",
       "2 -0.260551  0.389322 -0.321516 -0.636744  0.187596     0.0  \n",
       "3  0.280219  0.158491 -0.170124 -0.094134 -0.341412     1.0  \n",
       "4 -0.071234  0.248293  0.237985 -0.445129  0.144760     0.0  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(\"./train_features.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.018652</td>\n",
       "      <td>0.044593</td>\n",
       "      <td>0.626436</td>\n",
       "      <td>0.120929</td>\n",
       "      <td>-0.330582</td>\n",
       "      <td>-0.082190</td>\n",
       "      <td>0.404400</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.230142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085135</td>\n",
       "      <td>-0.684109</td>\n",
       "      <td>0.010689</td>\n",
       "      <td>0.347242</td>\n",
       "      <td>0.018564</td>\n",
       "      <td>0.077890</td>\n",
       "      <td>0.220567</td>\n",
       "      <td>-0.209710</td>\n",
       "      <td>-0.020969</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.046819</td>\n",
       "      <td>-0.007382</td>\n",
       "      <td>-0.430534</td>\n",
       "      <td>0.057031</td>\n",
       "      <td>-0.029240</td>\n",
       "      <td>-0.066380</td>\n",
       "      <td>0.195940</td>\n",
       "      <td>0.022584</td>\n",
       "      <td>-0.633248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516987</td>\n",
       "      <td>0.401136</td>\n",
       "      <td>-0.162690</td>\n",
       "      <td>0.313407</td>\n",
       "      <td>-0.526529</td>\n",
       "      <td>-0.005102</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>-0.253010</td>\n",
       "      <td>-0.230430</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.058761</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.142399</td>\n",
       "      <td>-0.294069</td>\n",
       "      <td>-0.064936</td>\n",
       "      <td>0.405668</td>\n",
       "      <td>-0.009982</td>\n",
       "      <td>0.118132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126814</td>\n",
       "      <td>-0.602803</td>\n",
       "      <td>0.034473</td>\n",
       "      <td>0.258250</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.073686</td>\n",
       "      <td>0.241751</td>\n",
       "      <td>-0.202604</td>\n",
       "      <td>0.015041</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.021341</td>\n",
       "      <td>0.022554</td>\n",
       "      <td>-0.043875</td>\n",
       "      <td>0.068697</td>\n",
       "      <td>-0.183094</td>\n",
       "      <td>-0.046553</td>\n",
       "      <td>0.265091</td>\n",
       "      <td>-0.026059</td>\n",
       "      <td>-0.373074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.321870</td>\n",
       "      <td>-0.036462</td>\n",
       "      <td>-0.131986</td>\n",
       "      <td>0.136839</td>\n",
       "      <td>-0.348797</td>\n",
       "      <td>0.081619</td>\n",
       "      <td>0.089043</td>\n",
       "      <td>-0.220117</td>\n",
       "      <td>-0.175350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.199597</td>\n",
       "      <td>-0.053690</td>\n",
       "      <td>-0.450743</td>\n",
       "      <td>0.117539</td>\n",
       "      <td>0.029594</td>\n",
       "      <td>-0.052182</td>\n",
       "      <td>0.370797</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>-0.604639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.445947</td>\n",
       "      <td>0.521602</td>\n",
       "      <td>-0.015426</td>\n",
       "      <td>0.120620</td>\n",
       "      <td>-0.446781</td>\n",
       "      <td>0.175845</td>\n",
       "      <td>0.066531</td>\n",
       "      <td>-0.383712</td>\n",
       "      <td>-0.068273</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 770 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0         1         2         3         4         5  \\\n",
       "0           0 -0.018652  0.044593  0.626436  0.120929 -0.330582 -0.082190   \n",
       "1           1  0.046819 -0.007382 -0.430534  0.057031 -0.029240 -0.066380   \n",
       "2           2 -0.058761  0.035549  0.609819  0.142399 -0.294069 -0.064936   \n",
       "3           3  0.021341  0.022554 -0.043875  0.068697 -0.183094 -0.046553   \n",
       "4           4 -0.199597 -0.053690 -0.450743  0.117539  0.029594 -0.052182   \n",
       "\n",
       "          6         7         8  ...       759       760       761       762  \\\n",
       "0  0.404400  0.007758  0.230142  ...  0.085135 -0.684109  0.010689  0.347242   \n",
       "1  0.195940  0.022584 -0.633248  ... -0.516987  0.401136 -0.162690  0.313407   \n",
       "2  0.405668 -0.009982  0.118132  ...  0.126814 -0.602803  0.034473  0.258250   \n",
       "3  0.265091 -0.026059 -0.373074  ... -0.321870 -0.036462 -0.131986  0.136839   \n",
       "4  0.370797  0.077776 -0.604639  ... -0.445947  0.521602 -0.015426  0.120620   \n",
       "\n",
       "        763       764       765       766       767  Labels  \n",
       "0  0.018564  0.077890  0.220567 -0.209710 -0.020969     1.0  \n",
       "1 -0.526529 -0.005102  0.008374 -0.253010 -0.230430     0.0  \n",
       "2  0.015367  0.073686  0.241751 -0.202604  0.015041     1.0  \n",
       "3 -0.348797  0.081619  0.089043 -0.220117 -0.175350     0.0  \n",
       "4 -0.446781  0.175845  0.066531 -0.383712 -0.068273     0.0  \n",
       "\n",
       "[5 rows x 770 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"./test_features.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop('Labels', axis='columns')\n",
    "y = train_df.pop('Labels')\n",
    "y = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('Labels', axis='columns')\n",
    "y_test = test_df.pop('Labels')\n",
    "y_test = y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier()  \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9616858237547893"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1: Best Fitness = 0.9664750957854407\n",
      "Generation 2: Best Fitness = 0.9655172413793104\n",
      "Generation 3: Best Fitness = 0.9655172413793104\n",
      "Generation 4: Best Fitness = 0.9664750957854407\n",
      "Generation 5: Best Fitness = 0.9664750957854407\n",
      "Selected Features: ['Unnamed: 0', '1', '2', '4', '5', '10', '15', '16', '18', '19', '21', '22', '24', '25', '27', '30', '31', '32', '33', '35', '37', '45', '47', '50', '55', '57', '59', '62', '66', '67', '68', '72', '74', '75', '76', '77', '80', '81', '82', '83', '87', '88', '89', '91', '93', '94', '95', '96', '97', '99', '101', '103', '104', '106', '108', '118', '119', '120', '121', '122', '124', '128', '132', '134', '136', '137', '141', '142', '143', '144', '145', '146', '147', '150', '152', '156', '161', '162', '164', '165', '166', '169', '170', '179', '180', '181', '182', '184', '186', '187', '188', '190', '191', '192', '193', '194', '198', '206', '210', '212', '215', '216', '224', '225', '226', '230', '233', '236', '237', '238', '243', '244', '245', '246', '250', '251', '253', '257', '259', '261', '263', '270', '272', '273', '275', '277', '278', '280', '281', '283', '286', '287', '288', '289', '291', '292', '293', '294', '295', '297', '299', '301', '303', '306', '308', '309', '314', '315', '316', '317', '319', '324', '328', '333', '334', '335', '339', '345', '349', '350', '351', '353', '354', '356', '357', '358', '359', '360', '363', '366', '367', '371', '372', '373', '375', '379', '381', '383', '385', '386', '388', '389', '393', '395', '400', '401', '403', '404', '405', '408', '410', '412', '414', '415', '417', '418', '420', '421', '424', '426', '428', '429', '432', '439', '441', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '456', '460', '463', '464', '465', '466', '467', '469', '470', '471', '472', '474', '475', '478', '479', '480', '482', '484', '485', '489', '494', '495', '497', '498', '500', '501', '502', '507', '508', '509', '511', '512', '513', '515', '516', '517', '520', '521', '522', '527', '531', '533', '534', '535', '536', '537', '538', '543', '544', '545', '546', '548', '550', '551', '553', '557', '558', '560', '561', '562', '565', '566', '567', '569', '571', '574', '576', '577', '580', '582', '583', '584', '585', '586', '587', '588', '589', '591', '593', '598', '600', '602', '603', '604', '606', '609', '611', '612', '615', '616', '619', '622', '623', '625', '631', '634', '636', '638', '640', '641', '643', '645', '647', '649', '650', '651', '654', '655', '657', '658', '660', '661', '662', '666', '667', '670', '672', '674', '675', '676', '685', '686', '688', '689', '691', '694', '696', '698', '699', '700', '705', '707', '709', '715', '717', '721', '722', '723', '726', '729', '730', '731', '732', '734', '736', '737', '738', '739', '742', '748', '749', '751', '752', '753', '754', '755', '761', '764', '766']\n",
      "375\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to evaluate the fitness of each chromosome\n",
    "def fitness(chromosome, X_train, X_test, y_train, y_test):\n",
    "    selected_features = [feature for feature, select in zip(X_train.columns, chromosome) if select == 1]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0  # Penalize solutions with no features selected\n",
    "    clf = RandomForestClassifier()  # You can use any classifier of your choice\n",
    "    clf.fit(X_train[selected_features], y_train)\n",
    "    y_pred = clf.predict(X_test[selected_features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Genetic Algorithm parameters\n",
    "population_size = 50\n",
    "num_generations = 5\n",
    "mutation_rate = 0.1\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize population\n",
    "population = np.random.randint(2, size=(population_size, X.shape[1]))\n",
    "\n",
    "# Main loop\n",
    "for generation in range(num_generations):\n",
    "    # Evaluate fitness of each chromosome\n",
    "    fitness_scores = [fitness(chromosome, X_train, X_test, y_train, y_test) for chromosome in population]\n",
    "    \n",
    "    # Select parents based on fitness scores\n",
    "    selected_indices = np.random.choice(range(population_size), size=population_size, replace=True, p=fitness_scores / np.sum(fitness_scores))\n",
    "    parents = population[selected_indices]\n",
    "    \n",
    "    # Crossover\n",
    "    crossover_point = np.random.randint(1, X.shape[1])\n",
    "    offspring = np.zeros_like(parents)\n",
    "    for i in range(0, population_size, 2):\n",
    "        parent1, parent2 = parents[i], parents[i+1]\n",
    "        offspring[i, :crossover_point] = parent1[:crossover_point]\n",
    "        offspring[i, crossover_point:] = parent2[crossover_point:]\n",
    "        offspring[i+1, :crossover_point] = parent2[:crossover_point]\n",
    "        offspring[i+1, crossover_point:] = parent1[crossover_point:]\n",
    "    \n",
    "    # Mutation\n",
    "    mutation_mask = np.random.rand(population_size, X.shape[1]) < mutation_rate\n",
    "    offspring ^= mutation_mask\n",
    "    \n",
    "    # Replace old population with offspring\n",
    "    population = offspring\n",
    "    \n",
    "    # Output best solution in current generation\n",
    "    best_solution_idx = np.argmax(fitness_scores)\n",
    "    best_solution = population[best_solution_idx]\n",
    "    best_fitness = fitness_scores[best_solution_idx]\n",
    "    print(f\"Generation {generation+1}: Best Fitness = {best_fitness}\")\n",
    "\n",
    "# Output the selected features\n",
    "selected_features = [feature for feature, select in zip(X.columns, best_solution) if select == 1]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96       469\n",
      "         1.0       0.96      0.98      0.97       575\n",
      "\n",
      "    accuracy                           0.97      1044\n",
      "   macro avg       0.97      0.97      0.97      1044\n",
      "weighted avg       0.97      0.97      0.97      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train[selected_features], y_train)\n",
    "y_pred = clf.predict(X_test[selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=True, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "xgb_clf.fit(X_train[selected_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96       469\n",
      "         1.0       0.96      0.97      0.96       575\n",
      "\n",
      "    accuracy                           0.96      1044\n",
      "   macro avg       0.96      0.96      0.96      1044\n",
      "weighted avg       0.96      0.96      0.96      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test[selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Global Best Fitness = 0.9674329501915708\n",
      "Iteration 2: Global Best Fitness = 0.9674329501915708\n",
      "Iteration 3: Global Best Fitness = 0.9674329501915708\n",
      "Iteration 4: Global Best Fitness = 0.9674329501915708\n",
      "Iteration 5: Global Best Fitness = 0.9674329501915708\n",
      "Selected Features: [  1   4   5   7   8   9  10  11  12  14  15  16  17  18  19  21  24  26\n",
      "  29  31  32  33  34  38  39  40  42  43  44  45  47  48  49  50  53  54\n",
      "  55  56  57  58  59  62  63  65  66  68  69  70  74  75  77  79  80  82\n",
      "  86  90  91  92  93  96  97  98 100 101 103 104 105 107 108 109 110 111\n",
      " 112 114 117 118 119 122 123 124 125 126 128 131 132 138 139 140 143 145\n",
      " 151 152 153 156 158 159 164 166 167 168 170 171 172 173 175 177 181 182\n",
      " 183 188 193 194 198 199 200 201 202 206 209 212 214 216 218 219 220 222\n",
      " 224 227 228 231 232 234 235 237 238 240 241 242 246 248 249 252 254 255\n",
      " 256 257 261 262 267 269 270 271 274 276 277 278 279 281 283 284 285 287\n",
      " 288 289 291 293 294 296 297 299 300 301 303 305 306 309 312 313 314 315\n",
      " 316 317 321 322 327 329 330 332 333 336 340 343 345 347 353 354 355 357\n",
      " 362 363 364 365 369 371 374 377 378 379 380 381 384 387 388 389 391 392\n",
      " 394 395 404 405 406 408 410 412 413 416 417 422 423 424 427 428 429 430\n",
      " 431 432 435 438 440 443 444 445 446 447 451 453 454 455 457 459 460 461\n",
      " 462 464 472 477 480 481 482 483 484 485 488 489 490 492 494 495 496 497\n",
      " 498 499 501 504 508 511 512 514 515 519 520 521 524 526 527 528 529 530\n",
      " 531 532 533 535 538 543 544 548 558 559 562 564 565 567 568 570 571 574\n",
      " 577 579 582 585 586 587 589 590 591 592 593 594 595 596 597 602 603 604\n",
      " 608 609 610 611 612 614 622 623 625 626 628 632 633 635 638 639 643 645\n",
      " 646 647 648 649 650 653 655 656 658 659 661 664 667 668 669 671 672 673\n",
      " 676 677 679 680 681 682 683 685 688 691 692 695 697 698 700 701 702 703\n",
      " 705 706 707 709 711 712 713 715 716 717 721 722 723 724 725 726 728 729\n",
      " 730 733 734 736 737 739 740 744 747 749 750 752 753 756 758 761 762 763\n",
      " 764 765 766 767]\n",
      "418\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Particle Swarm Optimization parameters\n",
    "num_particles = 60\n",
    "num_iterations = 5\n",
    "w = 0.5  # inertia weight\n",
    "c1 = 2.0  # cognitive weight\n",
    "c2 = 2.0  # social weight\n",
    "\n",
    "# Split data into features and labels\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define fitness function\n",
    "def fitness(features):\n",
    "    clf = RandomForestClassifier()  # You can use any classifier of your choice\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Initialize particles\n",
    "num_features = X.shape[1]\n",
    "particles = np.random.randint(2, size=(num_particles, num_features))  # Binary encoding of feature selection\n",
    "\n",
    "# Initialize particle velocities\n",
    "velocities = np.zeros((num_particles, num_features))\n",
    "\n",
    "# Initialize global best position and fitness\n",
    "global_best_position = None\n",
    "global_best_fitness = -np.inf\n",
    "\n",
    "# Main loop\n",
    "for iteration in range(num_iterations):\n",
    "    for i in range(num_particles):\n",
    "        # Evaluate fitness of current particle\n",
    "        current_fitness = fitness(np.where(particles[i])[0])\n",
    "        \n",
    "        # Update global best\n",
    "        if current_fitness > global_best_fitness:\n",
    "            global_best_fitness = current_fitness\n",
    "            global_best_position = np.copy(particles[i])\n",
    "        \n",
    "        # Update velocity\n",
    "        velocities[i] = (w * velocities[i] +\n",
    "                         c1 * np.random.rand() * (global_best_position - particles[i]) +\n",
    "                         c2 * np.random.rand() * (np.ones(num_features) - particles[i]))\n",
    "        \n",
    "        # Update position (binary flip with probability sigmoid(velocity))\n",
    "        probabilities = 1 / (1 + np.exp(-velocities[i]))\n",
    "        particles[i] = (np.random.rand(num_features) < probabilities).astype(int)\n",
    "    \n",
    "    # Print global best fitness in each iteration\n",
    "    print(f\"Iteration {iteration+1}: Global Best Fitness = {global_best_fitness}\")\n",
    "\n",
    "# Output the selected features\n",
    "selected_features = np.where(global_best_position)[0]\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   4,   5,   7,   8,   9,  10,  11,  12,  14,  15,  16,  17,\n",
       "        18,  19,  21,  24,  26,  29,  31,  32,  33,  34,  38,  39,  40,\n",
       "        42,  43,  44,  45,  47,  48,  49,  50,  53,  54,  55,  56,  57,\n",
       "        58,  59,  62,  63,  65,  66,  68,  69,  70,  74,  75,  77,  79,\n",
       "        80,  82,  86,  90,  91,  92,  93,  96,  97,  98, 100, 101, 103,\n",
       "       104, 105, 107, 108, 109, 110, 111, 112, 114, 117, 118, 119, 122,\n",
       "       123, 124, 125, 126, 128, 131, 132, 138, 139, 140, 143, 145, 151,\n",
       "       152, 153, 156, 158, 159, 164, 166, 167, 168, 170, 171, 172, 173,\n",
       "       175, 177, 181, 182, 183, 188, 193, 194, 198, 199, 200, 201, 202,\n",
       "       206, 209, 212, 214, 216, 218, 219, 220, 222, 224, 227, 228, 231,\n",
       "       232, 234, 235, 237, 238, 240, 241, 242, 246, 248, 249, 252, 254,\n",
       "       255, 256, 257, 261, 262, 267, 269, 270, 271, 274, 276, 277, 278,\n",
       "       279, 281, 283, 284, 285, 287, 288, 289, 291, 293, 294, 296, 297,\n",
       "       299, 300, 301, 303, 305, 306, 309, 312, 313, 314, 315, 316, 317,\n",
       "       321, 322, 327, 329, 330, 332, 333, 336, 340, 343, 345, 347, 353,\n",
       "       354, 355, 357, 362, 363, 364, 365, 369, 371, 374, 377, 378, 379,\n",
       "       380, 381, 384, 387, 388, 389, 391, 392, 394, 395, 404, 405, 406,\n",
       "       408, 410, 412, 413, 416, 417, 422, 423, 424, 427, 428, 429, 430,\n",
       "       431, 432, 435, 438, 440, 443, 444, 445, 446, 447, 451, 453, 454,\n",
       "       455, 457, 459, 460, 461, 462, 464, 472, 477, 480, 481, 482, 483,\n",
       "       484, 485, 488, 489, 490, 492, 494, 495, 496, 497, 498, 499, 501,\n",
       "       504, 508, 511, 512, 514, 515, 519, 520, 521, 524, 526, 527, 528,\n",
       "       529, 530, 531, 532, 533, 535, 538, 543, 544, 548, 558, 559, 562,\n",
       "       564, 565, 567, 568, 570, 571, 574, 577, 579, 582, 585, 586, 587,\n",
       "       589, 590, 591, 592, 593, 594, 595, 596, 597, 602, 603, 604, 608,\n",
       "       609, 610, 611, 612, 614, 622, 623, 625, 626, 628, 632, 633, 635,\n",
       "       638, 639, 643, 645, 646, 647, 648, 649, 650, 653, 655, 656, 658,\n",
       "       659, 661, 664, 667, 668, 669, 671, 672, 673, 676, 677, 679, 680,\n",
       "       681, 682, 683, 685, 688, 691, 692, 695, 697, 698, 700, 701, 702,\n",
       "       703, 705, 706, 707, 709, 711, 712, 713, 715, 716, 717, 721, 722,\n",
       "       723, 724, 725, 726, 728, 729, 730, 733, 734, 736, 737, 739, 740,\n",
       "       744, 747, 749, 750, 752, 753, 756, 758, 761, 762, 763, 764, 765,\n",
       "       766, 767], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96       469\n",
      "         1.0       0.96      0.97      0.96       575\n",
      "\n",
      "    accuracy                           0.96      1044\n",
      "   macro avg       0.96      0.96      0.96      1044\n",
      "weighted avg       0.96      0.96      0.96      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test.iloc[:, selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       469\n",
      "         1.0       0.96      0.97      0.97       575\n",
      "\n",
      "    accuracy                           0.96      1044\n",
      "   macro avg       0.96      0.96      0.96      1044\n",
      "weighted avg       0.96      0.96      0.96      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "xgb_clf.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred = xgb_clf.predict(X_test.iloc[:, selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIREFLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Firefly Algorithm parameters\n",
    "num_fireflies = 50\n",
    "num_iterations = 5\n",
    "beta0 = 1.0  # attractiveness scaling factor\n",
    "gamma = 0.1  # attractiveness absorption coefficient\n",
    "\n",
    "# Split data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define fitness function\n",
    "def fitness(features):\n",
    "    clf = RandomForestClassifier()  # You can use any classifier of your choice\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Initialize fireflies\n",
    "num_features = X.shape[1]\n",
    "fireflies = np.random.uniform(0, 1, size=(num_fireflies, num_features))  # Use floating-point numbers for positions\n",
    "\n",
    "# Main loop\n",
    "for iteration in range(num_iterations):\n",
    "    # Evaluate attractiveness of each firefly\n",
    "    attractiveness = np.array([fitness(np.where(firefly >= 0.5)[0]) for firefly in fireflies])  # Use binary threshold for feature selection\n",
    "    \n",
    "    # Update attractiveness of each firefly\n",
    "    for i in range(num_fireflies):\n",
    "        for j in range(num_fireflies):\n",
    "            if attractiveness[j] > attractiveness[i]:  # If firefly j is more attractive\n",
    "                distance = np.linalg.norm(fireflies[j] - fireflies[i])  # Euclidean distance between fireflies i and j\n",
    "                beta = beta0 * np.exp(-gamma * distance ** 2)  # Calculate attractiveness\n",
    "                fireflies[i] += beta * (fireflies[j] - fireflies[i])  # Move towards firefly j\n",
    "    \n",
    "    # Print global best fitness in each iteration\n",
    "    global_best_index = np.argmax(attractiveness)\n",
    "    global_best_fitness = attractiveness[global_best_index]\n",
    "    print(f\"Iteration {iteration+1}: Global Best Fitness = {global_best_fitness}\")\n",
    "    \n",
    "# Output the selected features\n",
    "selected_features = np.where(fireflies[global_best_index] >= 0.5)[0]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREY WOLF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define fitness function\n",
    "def fitness(features):\n",
    "    clf = RandomForestClassifier()  # You can use any classifier of your choice\n",
    "    try:\n",
    "        clf.fit(X_train.iloc[:, features], y_train)\n",
    "        y_pred = clf.predict(X_test.iloc[:, features])\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "    except:\n",
    "        ValueError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Global Best Fitness = 0.9664750957854407\n",
      "Iteration 2: Global Best Fitness = 0.9664750957854407\n",
      "Iteration 3: Global Best Fitness = 0.9655172413793104\n",
      "Iteration 4: Global Best Fitness = 0.9664750957854407\n",
      "Iteration 5: Global Best Fitness = 0.9674329501915708\n",
      "Selected Features: [  1   2   5   8   9  10  16  21  23  25  26  27  28  29  30  34  35  38\n",
      "  39  40  46  47  50  52  54  55  57  58  61  63  66  71  74  76  77  79\n",
      "  80  82  87  89  90  91  95  97  99 100 102 104 106 110 115 116 117 121\n",
      " 126 129 130 132 133 134 137 139 140 142 143 144 146 148 149 151 152 154\n",
      " 155 156 157 158 166 168 175 176 179 181 182 183 186 188 190 192 193 194\n",
      " 195 199 202 204 205 207 208 209 211 214 215 217 224 226 227 228 230 234\n",
      " 236 238 241 242 245 246 248 251 252 257 259 261 263 264 265 266 273 275\n",
      " 278 279 283 284 286 287 290 291 295 296 299 300 304 305 306 307 308 310\n",
      " 311 312 314 319 321 324 327 328 331 335 336 337 340 343 345 347 348 349\n",
      " 350 354 357 359 361 364 366 367 370 374 377 379 382 383 389 390 391 392\n",
      " 393 394 396 400 403 407 408 410 412 413 418 419 420 423 426 427 431 435\n",
      " 437 439 440 442 443 445 447 448 449 450 451 452 453 454 456 457 458 459\n",
      " 463 466 468 469 470 473 482 485 486 487 488 490 491 492 494 497 498 499\n",
      " 501 502 505 507 510 511 513 514 516 518 521 526 527 530 533 537 538 540\n",
      " 541 545 547 549 550 551 552 553 556 558 559 560 561 562 564 565 568 569\n",
      " 570 571 578 579 581 582 583 585 588 590 592 593 594 595 596 600 603 604\n",
      " 606 607 610 613 615 619 620 623 624 626 627 629 632 633 634 635 637 638\n",
      " 639 644 645 648 649 651 653 655 656 657 658 659 661 662 663 664 665 668\n",
      " 670 671 673 675 676 678 681 682 684 685 686 687 693 695 697 698 702 704\n",
      " 705 706 707 711 712 713 715 716 717 718 720 721 723 725 727 728 729 734\n",
      " 735 737 738 739 741 742 743 745 747 751 754 755 756 757 758 759 762 765\n",
      " 766 768]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Grey Wolf Optimizer parameters\n",
    "num_wolves = 50\n",
    "num_iterations = 5\n",
    "a = 2  # Parameter a\n",
    "C = 1  # Parameter C\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize positions of wolves randomly\n",
    "num_features = X.shape[1]\n",
    "positions = np.random.randint(2, size=(num_wolves, num_features))\n",
    "\n",
    "# Main loop\n",
    "for iteration in range(num_iterations):\n",
    "    # Update positions of wolves\n",
    "    a_linear = 2 - iteration * (2 / num_iterations)  # Linearly decreased from 2 to 0\n",
    "    for i in range(num_wolves):\n",
    "        for j in range(num_features):\n",
    "            r1 = np.random.rand()  # Random number between 0 and 1\n",
    "            r2 = np.random.rand()  # Random number between 0 and 1\n",
    "            A1 = 2 * a * r1 - a  # Equation (3.3)\n",
    "            C1 = 2 * r2  # Equation (3.4)\n",
    "            \n",
    "            # Update position of alpha wolf\n",
    "            if i == 0:\n",
    "                X_alpha = positions[i, j]\n",
    "                D_alpha = abs(C * X_alpha - positions[i, j])  # Equation (3.5)\n",
    "                positions[i, j] = X_alpha - A1 * D_alpha  # Equation (3.6)\n",
    "            # Update position of beta wolf\n",
    "            elif i == 1:\n",
    "                X_beta = positions[i, j]\n",
    "                D_beta = abs(C * X_beta - positions[i, j])  # Equation (3.7)\n",
    "                positions[i, j] = X_beta - A1 * D_beta  # Equation (3.8)\n",
    "            # Update position of delta wolf\n",
    "            elif i == 2:\n",
    "                X_delta = positions[i, j]\n",
    "                D_delta = abs(C * X_delta - positions[i, j])  # Equation (3.9)\n",
    "                positions[i, j] = X_delta - A1 * D_delta  # Equation (3.10)\n",
    "            # Update position of other wolves\n",
    "            else:\n",
    "                D1 = abs(C * positions[i, j] - positions[i, j])  # Equation (3.11)\n",
    "                positions[i, j] = positions[i, j] - A1 * D1  # Equation (3.12)\n",
    "    \n",
    "    # Search for prey (solutions)\n",
    "    solutions = positions\n",
    "    \n",
    "    # Evaluate fitness of each solution\n",
    "    fitness_scores = np.array([fitness(np.where(solution==1)[0]) for solution in solutions])\n",
    "    fitness_scores = fitness_scores[fitness_scores != None]\n",
    "    # Update alpha, beta, and delta wolves\n",
    "    alpha_index = np.argmax(fitness_scores)\n",
    "    alpha_position = positions[alpha_index]\n",
    "    \n",
    "    beta_indices = np.argsort(fitness_scores)[-2:]  # Get indices of top 2 wolves\n",
    "    beta_positions = positions[beta_indices]\n",
    "    \n",
    "    delta_index = np.argmin(fitness_scores)\n",
    "    delta_position = positions[delta_index]\n",
    "    \n",
    "    # Print global best fitness in each iteration\n",
    "    global_best_fitness = fitness_scores[alpha_index]\n",
    "    print(f\"Iteration {iteration+1}: Global Best Fitness = {global_best_fitness}\")\n",
    "\n",
    "# Output the selected features\n",
    "selected_features = np.where(alpha_position == 1)[0]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "380"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96       469\n",
      "         1.0       0.97      0.97      0.97       575\n",
      "\n",
      "    accuracy                           0.96      1044\n",
      "   macro avg       0.96      0.96      0.96      1044\n",
      "weighted avg       0.96      0.96      0.96      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred = clf.predict(X_test.iloc[:, selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.96       469\n",
      "         1.0       0.96      0.97      0.96       575\n",
      "\n",
      "    accuracy                           0.96      1044\n",
      "   macro avg       0.96      0.96      0.96      1044\n",
      "weighted avg       0.96      0.96      0.96      1044\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(tree_method=\"hist\", enable_categorical=True)\n",
    "xgb_clf.fit(X_train.iloc[:, selected_features], y_train)\n",
    "y_pred = xgb_clf.predict(X_test.iloc[:, selected_features])\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = fitness_scores[fitness_scores != None]\n",
    "np.argmax(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for solution in solutions:\n",
    "    fitness(np.where(solution==1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KOOKABURA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Global Best Fitness = 0.9912280701754386\n",
      "Iteration 2: Global Best Fitness = 0.9736842105263158\n",
      "Iteration 3: Global Best Fitness = 0.9736842105263158\n",
      "Iteration 4: Global Best Fitness = 0.9649122807017544\n",
      "Iteration 5: Global Best Fitness = 0.9649122807017544\n",
      "Selected Features: [ 4  5 14 15 17 18 19 28]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Kookaburra Optimization Algorithm parameters\n",
    "num_kookaburras = 50\n",
    "num_iterations = 5\n",
    "alpha = 0.1  # Alpha parameter\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define fitness function\n",
    "def fitness(features):\n",
    "    clf = RandomForestClassifier()  # You can use any classifier of your choice\n",
    "    clf.fit(X_train.iloc[:, features], y_train)\n",
    "    y_pred = clf.predict(X_test.iloc[:, features])\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Initialize positions of kookaburras randomly\n",
    "num_features = X.shape[1]\n",
    "positions = np.random.randint(2, size=(num_kookaburras, num_features))\n",
    "\n",
    "# Main loop\n",
    "for iteration in range(num_iterations):\n",
    "    # Evaluate fitness of each kookaburra\n",
    "    fitness_scores = np.array([fitness(np.where(kookaburra==1)[0]) for kookaburra in positions])\n",
    "    \n",
    "    # Sort kookaburras based on fitness scores\n",
    "    sorted_indices = np.argsort(fitness_scores)\n",
    "    sorted_positions = positions[sorted_indices]\n",
    "    \n",
    "    # Update positions of kookaburras\n",
    "    for i in range(num_kookaburras):\n",
    "        for j in range(num_features):\n",
    "            rand = np.random.rand()  # Random number between 0 and 1\n",
    "            if rand < alpha:  # Perform exploration\n",
    "                positions[i, j] = np.random.randint(2)\n",
    "            else:  # Perform exploitation\n",
    "                positions[i, j] = sorted_positions[np.random.randint(3)][j]  # Select from top 3 kookaburras\n",
    "    \n",
    "    # Print global best fitness in each iteration\n",
    "    global_best_fitness = fitness_scores[sorted_indices[-1]]\n",
    "    print(f\"Iteration {iteration+1}: Global Best Fitness = {global_best_fitness}\")\n",
    "\n",
    "# Output the selected features\n",
    "selected_features = np.where(positions[np.argmax(fitness_scores)] == 1)[0]\n",
    "print(\"Selected Features:\", selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), array([ 0,  1,  2,  4,  7, 10, 12, 13, 14, 15, 19, 21, 23, 27],\n      dtype=int64))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:158\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), array([ 0,  1,  2,  4,  7, 10, 12, 13, 14, 15, 19, 21, 23, 27],\n      dtype=int64))' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m selected_features\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mant_colony_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mant_colony_optimization\u001b[1;34m(X, y, num_ants, num_iterations, evaporation_rate, alpha, beta, random_state)\u001b[0m\n\u001b[0;32m     26\u001b[0m ants \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39m(num_ants, num_features))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate fitness of each ant\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mant\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mant\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mants\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Update pheromone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_ants):\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     26\u001b[0m ants \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m2\u001b[39m, size\u001b[38;5;241m=\u001b[39m(num_ants, num_features))\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Evaluate fitness of each ant\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m fitness \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mant\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m ant \u001b[38;5;129;01min\u001b[39;00m ants])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Update pheromone\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_ants):\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mant_colony_optimization.<locals>.evaluate\u001b[1;34m(features)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(features):\n\u001b[0;32m     14\u001b[0m     clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)  \u001b[38;5;66;03m# You can use any classifier of your choice\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     clf\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m, y_train)\n\u001b[0;32m     16\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(X_test[:, features])\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3803\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KARAN\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5974\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5971\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5972\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5973\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), array([ 0,  1,  2,  4,  7, 10, 12, 13, 14, 15, 19, 21, 23, 27],\n      dtype=int64))"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Function to implement Ant Colony Optimization for feature selection\n",
    "def ant_colony_optimization(X, y, num_ants=20, num_iterations=5, evaporation_rate=0.5, alpha=1, beta=2, random_state=42):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    # Define fitness function\n",
    "    def evaluate(features):\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=random_state)  # You can use any classifier of your choice\n",
    "        clf.fit(X_train[:, features], y_train)\n",
    "        y_pred = clf.predict(X_test[:, features])\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Initialize pheromone\n",
    "    num_features = X.shape[1]\n",
    "    pheromone = np.ones(num_features)\n",
    "    \n",
    "    # Main loop\n",
    "    for iteration in range(num_iterations):\n",
    "        # Initialize ants\n",
    "        ants = np.random.randint(2, size=(num_ants, num_features))\n",
    "\n",
    "        # Evaluate fitness of each ant\n",
    "        fitness = np.array([evaluate(np.where(ant==1)[0]) for ant in ants])\n",
    "        \n",
    "        # Update pheromone\n",
    "        for i in range(num_ants):\n",
    "            for j in range(num_features):\n",
    "                rand = np.random.rand()  # Random number between 0 and 1\n",
    "                if rand < alpha:  # Exploration\n",
    "                    ants[i, j] = np.random.randint(2)\n",
    "                else:  # Exploitation\n",
    "                    probabilities = pheromone ** alpha / (X.sum(axis=0) ** beta)\n",
    "                    probabilities /= probabilities.sum()\n",
    "                    ants[i, j] = 1 if np.random.rand() < probabilities[j] else 0\n",
    "        \n",
    "        # Update pheromone\n",
    "        pheromone *= (1 - evaporation_rate)\n",
    "        for i, ant in enumerate(ants):\n",
    "            fitness_score = fitness[i]\n",
    "            for j, feature in enumerate(ant):\n",
    "                pheromone[j] += evaporation_rate * feature * fitness_score\n",
    "        \n",
    "        # Print global best fitness in each iteration\n",
    "        global_best_fitness = np.max(fitness)\n",
    "        print(f\"Iteration {iteration+1}: Global Best Fitness = {global_best_fitness}\")\n",
    "\n",
    "    # Output the selected features\n",
    "    selected_features = np.where(ants[np.argmax(fitness)] == 1)[0]\n",
    "    print(\"Selected Features:\", selected_features)\n",
    "    return selected_features\n",
    "\n",
    "# Example usage\n",
    "selected_features = ant_colony_optimization(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
